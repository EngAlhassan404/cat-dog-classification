{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcjtLH4Rmb2ErnfuumxBLA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7NzcvffXohok"},"outputs":[],"source":["# كود التجهيز الأولي لربط جوجل درايف ورفع ملفات API\n","# -*- coding: utf-8 -*-\n","# استيراد مكتبة جوجل درايف\n","from google.colab import drive\n","# استيراد مكتبة التعامل مع الملفات في جوجل كولاب\n","from google.colab import files\n","\n","# تثبيت أي مكتبات ضرورية\n","!pip install kaggle\n","\n","# طلب ربط الحساب وتحديد نقطة الوصول\n","drive.mount('/content/drive')\n","\n","\n","# --- رفع ملفات API ---\n","\n","# 1. رفع ملف Kaggle API\n","print('Please upload the \"kaggle.json\" file:')\n","files.upload()\n","\n","# 2. رفع ملف Unsplash API (تمت إضافة هذا الجزء)\n","print('\\nPlease upload the \"Unsplash.json\" file:')\n","files.upload()\n","\n","\n","# --- إعداد Kaggle API ---\n","\n","# إنشاء مجلد مخفي باسم .kaggle في الدليل الرئيسي\n","!mkdir -p ~/.kaggle\n","\n","# نسخ ملف كاجل الذي تم رفعه إلى المجلد الجديد\n","!cp kaggle.json ~/.kaggle/\n","\n","# تعيين أذونات القراءة والكتابة للمستخدم فقط\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","print(\"\\n--- Setup Complete. Both Kaggle and Unsplash API files are ready. ---\")"]},{"cell_type":"code","source":["#  تحضير بيانات صور للكلاب والقطط من كاجل للاختبار\n","\n","# -*- coding: utf-8 -*-\n","import kagglehub\n","import os\n","\n","# --- الخطوة 1: تحميل مسار مجموعة البيانات ---\n","print(\"--- Downloading path for the new dataset: 'tongpython/cat-and-dog' ---\")\n","new_dataset_path = kagglehub.dataset_download(\"tongpython/cat-and-dog\")\n","print(f\"\\nDataset path: {new_dataset_path}\")\n","\n","# --- الخطوة 2: استكشاف هيكل المجلدات والملفات ---\n","# نستخدم الأمر ls -R لعرض كل المحتويات بشكل شجري\n","# قد يستغرق هذا الأمر بعض الوقت لأن البيانات كثيرة\n","print(\"\\n--- Exploring the directory structure... ---\")\n","!ls -R {new_dataset_path}"],"metadata":{"id":"vNKLUPqMonfB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# الاختبار على بيانات صور للكلاب والقطط من كاجل\n","\n","# -*- coding: utf-8 -*-\n","import tensorflow as tf\n","import os\n","import numpy as np\n","import time\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","# =================================================================\n","# الخطوة 1: تحميل النموذج وتحديد المسارات\n","# =================================================================\n","print(\"--- Loading the best trained model... ---\")\n","best_model_path = \"/content/drive/MyDrive/ML_Cat_Dog_Project/checkpoints/best_model.keras\"\n","model = tf.keras.models.load_model(best_model_path)\n","print(\"Model loaded successfully.\")\n","\n","path_to_training_data = os.path.join(new_dataset_path, 'training_set', 'training_set')\n","path_to_test_data = os.path.join(new_dataset_path, 'test_set', 'test_set')\n","\n","# =================================================================\n","# الخطوة 2: جمع مسارات الصور وتسمياتها الحقيقية\n","# =================================================================\n","all_image_paths = []\n","all_image_labels = []\n","class_names = ['cats', 'dogs']\n","\n","def collect_paths_and_labels(data_dir, label_name):\n","    label_index = class_names.index(label_name)\n","    class_dir = os.path.join(data_dir, label_name)\n","    if os.path.exists(class_dir):\n","        for f in os.listdir(class_dir):\n","            all_image_paths.append(os.path.join(class_dir, f))\n","            all_image_labels.append(label_index)\n","\n","for data_dir in [path_to_training_data, path_to_test_data]:\n","    if os.path.exists(data_dir):\n","        collect_paths_and_labels(data_dir, 'cats')\n","        collect_paths_and_labels(data_dir, 'dogs')\n","print(f\"\\nFound a total of {len(all_image_paths)} file paths to process.\")\n","\n","\n","# =================================================================\n","# الخطوة 3: بناء خط إمداد بيانات قوي\n","# =================================================================\n","IMG_SIZE = (180, 180)\n","BATCH_SIZE = 64\n","\n","def load_and_decode_image(filepath, label):\n","    try:\n","        img_bytes = tf.io.read_file(filepath)\n","        img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n","        img = tf.image.resize(img, IMG_SIZE)\n","        return img, label, True\n","    except:\n","        return tf.zeros((IMG_SIZE[0], IMG_SIZE[1], 3)), tf.constant(-1, dtype=tf.int32), False\n","\n","full_ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n","processed_ds = full_ds.map(lambda fp, lbl: tf.py_function(load_and_decode_image, [fp, lbl], [tf.float32, tf.int32, tf.bool]))\n","valid_ds = processed_ds.filter(lambda img, lbl, success: success)\n","\n","# --- تم تصحيح هذا الجزء ---\n","# استخراج التسميات الحقيقية باستخدام np.array بدلاً من np.concatenate\n","y_true = np.array([y for x, y, z in valid_ds])\n","images_only_ds = valid_ds.map(lambda x, y, z: x)\n","\n","batched_ds = images_only_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","# =================================================================\n","# الخطوة 4: تشغيل التنبؤات وحساب المقاييس\n","# =================================================================\n","print(\"\\n--- Starting prediction on all valid images... ---\")\n","start_time = time.time()\n","y_pred_probs = model.predict(batched_ds, verbose=1)\n","end_time = time.time()\n","print(f\"Prediction finished in {end_time - start_time:.2f} seconds.\")\n","\n","y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n","\n","print(\"\\n--- Calculating final metrics... ---\")\n","accuracy = accuracy_score(y_true, y_pred_classes)\n","cm = confusion_matrix(y_true, y_pred_classes)\n","class_report = classification_report(y_true, y_pred_classes, target_names=class_names, zero_division=0)\n","\n","# =================================================================\n","# الخطوة 5: بناء وحفظ التقرير النهائي\n","# =================================================================\n","timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n","report_string = f\"\"\"\n","=================================================\n","      FULL PERFORMANCE REPORT (LARGE DATASET)\n","=================================================\n","Test Time: {timestamp}\n","Dataset Source: tongpython/cat-and-dog\n","Total Images Processed: {len(y_true)}\n","-------------------------------------------------\n","\n","### OVERALL ACCURACY ###\n","Accuracy: {accuracy:.2%}\n","\n","-------------------------------------------------\n","\n","### CLASSIFICATION REPORT ###\n","{class_report}\n","\n","-------------------------------------------------\n","\n","### TEXT-BASED CONFUSION MATRIX ###\n","\n","                 Predicted Cat | Predicted Dog\n","               ----------------|----------------\n","    Actual Cat |      {cm[0, 0]:<7} |      {cm[0, 1]:<7}\n","    Actual Dog |      {cm[1, 0]:<7} |      {cm[1, 1]:<7}\n","\n","-------------------------------------------------\n","Matrix Details:\n","- True Cats (TN): {cm[0, 0]}\n","- False Dogs (FP): {cm[0, 1]}  (Cat predicted as Dog)\n","- False Cats (FN): {cm[1, 0]}  (Dog predicted as Cat)\n","- True Dogs (TP): {cm[1, 1]}\n","=================================================\n","\"\"\"\n","\n","report_dir = \"/content/drive/MyDrive/ML_Cat_Dog_Project/test_reports\"\n","os.makedirs(report_dir, exist_ok=True)\n","report_filename = f\"large_dataset_report_{time.strftime('%Y%m%d-%H%M%S')}.txt\"\n","report_path = os.path.join(report_dir, report_filename)\n","with open(report_path, 'w') as f:\n","    f.write(report_string)\n","\n","print(f\"\\n---> Detailed performance report saved to: {report_path} <---\")\n","print(report_string)"],"metadata":{"id":"mzzleefIo1-6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# تجربة جلب صور من الانترنت من موقع Unsplash عبر API عدد الصور 60 صورة\n","# -*- coding: utf-8 -*-\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","import requests\n","import json\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","# =================================================================\n","# الخطوة 1: تحميل الإعدادات (لا تغيير هنا)\n","# =================================================================\n","print(\"--- Loading required assets (model and API keys)... ---\")\n","best_model_path = \"/content/drive/MyDrive/ML_Cat_Dog_Project/checkpoints/best_model.keras\"\n","model = tf.keras.models.load_model(best_model_path)\n","print(\"Best model loaded successfully.\")\n","\n","with open('Unsplash.json') as f:\n","    secrets = json.load(f)\n","    unsplash_access_key = secrets['unsplash_access_key']\n","print(\"Unsplash API key loaded successfully.\")\n","\n","# =================================================================\n","# الخطوة 2: تعريف الدوال الأساسية (مع تبسيط دالة الجلب)\n","# =================================================================\n","IMG_SIZE = (180, 180)\n","HEADERS = {'Authorization': f'Client-ID {unsplash_access_key}'}\n","class_names = ['cats', 'dogs']\n","\n","# --- تم تبسيط هذه الدالة ---\n","def fetch_and_predict(search_query, true_label_index, num_images_to_get):\n","    \"\"\"\n","    دالة تقوم بطلب واحد لجلب دفعة من الصور وتصنيفها.\n","    \"\"\"\n","    print(f\"\\n--- Starting process for query: '{search_query}' ---\")\n","    y_true_class, y_pred_class = [], []\n","\n","    # سنقوم بطلب واحد فقط مع تحديد العدد (الحد الأقصى 30)\n","    api_url = f\"https://api.unsplash.com/search/photos?query={search_query}&per_page={num_images_to_get}\"\n","\n","    try:\n","        response = requests.get(api_url, headers=HEADERS)\n","        response.raise_for_status()\n","        data = response.json()\n","\n","        for item in data['results']:\n","            image_url = item['urls']['regular']\n","            try:\n","                image_response = requests.get(image_url, stream=True)\n","                image_response.raise_for_status()\n","\n","                img_bytes = tf.constant(image_response.content)\n","                img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n","                img = tf.image.resize(img, IMG_SIZE)\n","                img_array = tf.expand_dims(img, 0)\n","\n","                prediction = model.predict(img_array, verbose=0)\n","                predicted_class_index = 1 if prediction[0][0] > 0.5 else 0\n","\n","                y_true_class.append(true_label_index)\n","                y_pred_class.append(predicted_class_index)\n","            except Exception:\n","                continue # تجاهل أي صورة تفشل في التحميل\n","\n","    except requests.exceptions.RequestException as e:\n","        print(f\"API request failed. Error: {e}\")\n","\n","    print(f\"Successfully processed {len(y_true_class)} images for '{search_query}'.\")\n","    return y_true_class, y_pred_class\n","\n","# =================================================================\n","# الخطوة 3: تنفيذ الاختبار وجمع النتائج\n","# =================================================================\n","# --- تم تعديل العدد هنا إلى 30 ---\n","NUM_IMAGES_PER_CLASS = 30\n","\n","y_true_cats, y_pred_cats = fetch_and_predict('cat', 0, NUM_IMAGES_PER_CLASS)\n","y_true_dogs, y_pred_dogs = fetch_and_predict('dog', 1, NUM_IMAGES_PER_CLASS)\n","\n","y_true_final = y_true_cats + y_true_dogs\n","y_pred_final = y_pred_cats + y_pred_dogs\n","\n","# =================================================================\n","# الخطوة 4: حساب المقاييس وإنشاء التقرير (لا تغيير هنا)\n","# =================================================================\n","print(\"\\n--- All images processed. Calculating final metrics... ---\")\n","if not y_true_final:\n","    print(\"No images were successfully processed. Cannot generate report.\")\n","else:\n","    # ... (بقية كود إنشاء التقرير وحفظه كما هو) ...\n","    accuracy = accuracy_score(y_true_final, y_pred_final)\n","    cm = confusion_matrix(y_true_final, y_pred_final)\n","    class_report = classification_report(y_true_final, y_pred_final, target_names=class_names, zero_division=0)\n","\n","    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n","    report_string = f\"\"\"\n","=================================================\n","      UNSPLASH API TEST - PERFORMANCE REPORT\n","=================================================\n","Test Time: {timestamp}\n","Target Images Per Class: {NUM_IMAGES_PER_CLASS}\n","Total Images Processed: {len(y_true_final)}\n","-------------------------------------------------\n","### OVERALL ACCURACY ###\n","Accuracy: {accuracy:.2%}\n","-------------------------------------------------\n","### CLASSIFICATION REPORT ###\n","{class_report}\n","-------------------------------------------------\n","### TEXT-BASED CONFUSION MATRIX ###\n","                 Predicted Cat | Predicted Dog\n","               ----------------|----------------\n","    Actual Cat |      {cm[0, 0]:<7} |      {cm[0, 1]:<7}\n","    Actual Dog |      {cm[1, 0]:<7} |      {cm[1, 1]:<7}\n","-------------------------------------------------\n","Matrix Details:\n","- True Cats (TN): {cm[0, 0]}\n","- False Dogs (FP): {cm[0, 1]}  (Cat predicted as Dog)\n","- False Cats (FN): {cm[1, 0]}  (Dog predicted as Cat)\n","- True Dogs (TP): {cm[1, 1]}\n","=================================================\n","\"\"\"\n","    report_dir = \"/content/drive/MyDrive/ML_Cat_Dog_Project/test_reports\"\n","    os.makedirs(report_dir, exist_ok=True)\n","    report_filename = f\"unsplash_report_{time.strftime('%Y%m%d-%H%M%S')}.txt\"\n","    report_path = os.path.join(report_dir, report_filename)\n","    with open(report_path, 'w') as f:\n","        f.write(report_string)\n","    print(f\"\\n---> Detailed performance report saved to: {report_path} <---\")\n","    print(report_string)"],"metadata":{"id":"y3X6twuapGLn"},"execution_count":null,"outputs":[]}]}